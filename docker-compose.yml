services:
  db:
    image: postgres:15
    environment:
      POSTGRES_USER: appuser
      POSTGRES_PASSWORD: applongpass
      POSTGRES_DB: chatbot
    ports:
      - "5433:5432"
    volumes:
      - dbdata:/var/lib/postgresql/data
      - ./scripts/seed.sql:/docker-entrypoint-initdb.d/seed.sql:ro
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U appuser -d chatbot"]
      interval: 5s
      timeout: 5s
      retries: 10

  redis:
    image: redis:7-alpine
    ports:
      - "6380:6379"
    volumes:
      - redisdata:/data

  backend:
    build: ./backend
    environment:
      NODE_ENV: development
      PORT: 4000
      DATABASE_URL: ${DATABASE_URL}
      REDIS_URL: ${REDIS_URL}
      OPENAI_API_KEY: ${OPENAI_API_KEY}
      JWT_ACCESS_SECRET: ${JWT_ACCESS_SECRET}
      JWT_REFRESH_SECRET: ${JWT_REFRESH_SECRET}
      ALLOWED_ORIGINS: ${ALLOWED_ORIGINS}
      TELEGRAM_BOT_TOKEN: ${TELEGRAM_BOT_TOKEN}
      SLACK_BOT_TOKEN: ${SLACK_BOT_TOKEN}
      SLACK_SIGNING_SECRET: ${SLACK_SIGNING_SECRET}
    ports:
      - "4000:4000"
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_started

  frontend:
    build: ./frontend
    environment:
      VITE_API_URL: http://localhost:4000
    ports:
      - "5173:5173"
    depends_on:
      - backend


  llama-server:
    image: ghcr.io/ggerganov/llama.cpp:server
    ports:
      - "8081:8080"
    volumes:
      - ./models:/models
    environment:
      - MODEL=/models/vox_legacy.gguf
      - HOST=0.0.0.0
      - PORT=8080
      - THREADS=4
      - CONTEXT_SIZE=1024
    command: ["--model", "/models/vox_legacy.gguf", "--host", "0.0.0.0", "--port", "8080", "--threads", "4", "--ctx-size", "1024", "--batch-size", "1", "--n-gpu-layers", "0"]
    networks:
      - default

  nginx:
    image: nginx:1.27-alpine
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
    ports:
      - "8080:80"
    depends_on:
      - frontend
      - backend

volumes:
  dbdata: {}
  redisdata: {}
